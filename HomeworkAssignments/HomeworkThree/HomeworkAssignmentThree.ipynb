{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf356ab",
   "metadata": {},
   "source": [
    "**Exercise 1: (5 points) You are given a dataset having more variables than observations. Assuming that\n",
    "there seems to be a linear relationship between the target variable and the input variables in the\n",
    "dataset, why ordinary least squares (OLS) is a bad option to estimate the model parameters?\n",
    "Which technique would be best to use? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f37224",
   "metadata": {},
   "source": [
    "Since the number of input variables is larger than the number of observations in the dataset, there is no longer a unique least squares coefficient and the variance is infinite. So the least squares method cannot be used at all. Also, least squares is very unlikely to yield any coefficients of that are exactly 0, which doesn't allow us to use it as a variable selection procedure. I would use lasso in this situation in the hopes of eliminating unnecessary variables that add complexity and aren't significant when creating the actual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045bdba8",
   "metadata": {},
   "source": [
    "**Exercise 2: (5 points) For Ridge regression, if the regularization parameter, λ, is equal to 0, what are the\n",
    "implications?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44409e5d",
   "metadata": {},
   "source": [
    "(d) All of the above. Because when λ = 0 the penalty term has no effect and ridge regression will produce the least squares estimates. So  regularization isn't technically used at all. Therefore, since it doesn't change the model, it doesn't really account for overfitting either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a17db",
   "metadata": {},
   "source": [
    "**Exercise 3: (5 points) For Lasso Regression, if the regularization parameter, λ, is very high, which options are\n",
    "true? Select all that apply.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3da47",
   "metadata": {},
   "source": [
    "(f) (a) and (b). It can be used to select important features of a dataset and shrinks the coefficients of less important features to exactly 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c614d",
   "metadata": {},
   "source": [
    "**Exercise 4:\n",
    "An important theoretical result of statistics and Machine Learning is the fact that model’s gener\u0002alization error can be expressed as the sum of two very different errors:**\n",
    "- **Bias: This part of the generalization error is due to wrong assumptions, such as assuming that the data is linear when it is actually quadratic. A high-bias model is most likely to under-fit the training data.**\n",
    "- **Variance: This part is due to the model’s excessive sensitivity to small variations in the training data. A model with many degrees of freedom (such as a high-degree polynomial model) is likely to have high variance and thus overfit the training data.**\n",
    "\n",
    "**(5 points) Suppose you are using Ridge Regression and you notice that the training error and\n",
    "the validation error are almost equal and fairly high. Would you say that the model suffers from\n",
    "high bias or high variance? Should you increase the regularization parameter, λ, or reduce it?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936217f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4948f060",
   "metadata": {},
   "source": [
    "**Exercise 5: Consider the CarPrice Assignment.csv data file. This data is public available on the Kaggle\n",
    "website, and has information on cars (characteristics related to car dimensions, engine and more).\n",
    "The goal is to use car information to predict the price of the car. In Python, answer the following:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb21fc",
   "metadata": {},
   "source": [
    "(a) (5 points) Load the data file to you S3 bucket. Using the pandas library, read the csv data file and create a data-frame called car price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b3055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6e22cef",
   "metadata": {},
   "source": [
    "(b) (15 points) Using the wheelbase, enginesize, compressionratio, horsepower, peakrpm, citympg, and highwaympg as the predictor variables, and price is the target variable. Do the following:\n",
    "\n",
    "- Split the data into train (80%) and test (20%)\n",
    "- Using the train dataset: \n",
    " - Estimate the optimal lambda using default values for lambda in scikit-learn and 5-folds. Make sure to normalize the data (normalize = True).\n",
    " - Perform LASSO as a variable selector (using the optimal lambda from previous step (i)). Make sure to normalize the data (normalize = True).\n",
    "\n",
    "Repeat steps (1) and (2) 1000 times. Store the estimated model coefficients of each iteration\n",
    "in a data-frame. Remove the variables, whose estimated coefficients is 0 more than 500\n",
    "times, from the training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2743298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af0606a8",
   "metadata": {},
   "source": [
    "(c) (5 points) Split the data into train (80%) and test (20%). Then, normalize the inputs variables of the train and test datasets using the L2 normalization. That is, for each input variable subtract the mean of that variable, then divide by the L2-norm of that variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58467072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de52cd4",
   "metadata": {},
   "source": [
    "(d) (5 points) Using the train dataset, build a linear regression model. After that, use this model to predict on the test dataset. Report the MSE of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079151a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7593ea2b",
   "metadata": {},
   "source": [
    "(e) (10 points) Using the train dataset, build a Ridge regression model as follows:\n",
    "- Using the train dataset, estimate the optimal lambda from the following set [0.001, 0.01, 0.1, 1, 10, 100] and using 5-folds.\n",
    "- Repeat (i) 100, store the optimal lambda of each iteration.\n",
    "\n",
    "Using the most common lambda of the 100 optimal lambdas and the train dataset, build a Ridge regression model. After that, use this model to predict on the test dataset. Report the MSE of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7744f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8542525f",
   "metadata": {},
   "source": [
    "(f) (5 points) Using the results from parts (d) and (e), what model would you use to predict car prices? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ab88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
